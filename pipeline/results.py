"""
Results Management and Visualization

Manages result storage, visualization, and reporting for quantum
layout optimization comparisons. Provides plotting and export
capabilities for hackathon demonstrations.
"""

from typing import Dict, List, Any, Optional
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from pathlib import Path


class ResultsManager:
    """
    Manages visualization and export of transpilation comparison results.
    
    Provides comprehensive plotting capabilities and export functions
    optimized for hackathon presentations and analysis.
    """
    
    def __init__(self, output_dir: str = "results"):
        """
        Initialize results manager.
        
        Args:
            output_dir: Directory for saving plots and exports
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Set plotting style
        plt.style.use('default')
        sns.set_palette("husl")
        
    def create_comparison_plots(self, 
                              metrics_df: pd.DataFrame,
                              save_plots: bool = True,
                              show_plots: bool = True) -> None:
        """
        Create comprehensive comparison plots.
        
        Args:
            metrics_df: DataFrame with transpilation metrics
            save_plots: Whether to save plots to disk
            show_plots: Whether to display plots
        """
        if metrics_df.empty:
            print("‚ö†Ô∏è  No data available for plotting")
            return
        
        # Filter successful comparisons
        df = metrics_df[metrics_df['custom_success'] & metrics_df['stock_success']].copy()
        
        if df.empty:
            print("‚ö†Ô∏è  No successful comparisons to plot")
            return
        
        # Create multi-panel figure
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Quantum Layout Optimization Results', fontsize=16, fontweight='bold')
        
        # Plot 1: CX Reduction vs Circuit Size
        ax1 = axes[0, 0]
        scatter = ax1.scatter(df['num_qubits'], df['cx_reduction_percent'], 
                            c=df['custom_compile_time'], cmap='viridis', alpha=0.7, s=60)
        ax1.set_xlabel('Number of Qubits')
        ax1.set_ylabel('CX Reduction (%)')
        ax1.set_title('CX Gate Reduction vs Circuit Size')
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)
        plt.colorbar(scatter, ax=ax1, label='Compile Time (s)')
        
        # Plot 2: CX Count Comparison
        ax2 = axes[0, 1]
        ax2.scatter(df['stock_cx_count'], df['custom_cx_count'], alpha=0.7, s=60)
        ax2.plot([df['stock_cx_count'].min(), df['stock_cx_count'].max()], 
                [df['stock_cx_count'].min(), df['stock_cx_count'].max()], 
                'r--', alpha=0.5, label='No improvement')
        ax2.set_xlabel('Stock CX Count')
        ax2.set_ylabel('Custom CX Count')
        ax2.set_title('CX Count: Custom vs Stock')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # Plot 3: Compilation Time Comparison
        ax3 = axes[0, 2]
        ax3.scatter(df['stock_compile_time'], df['custom_compile_time'], alpha=0.7, s=60)
        ax3.plot([df['stock_compile_time'].min(), df['stock_compile_time'].max()], 
                [df['stock_compile_time'].min(), df['stock_compile_time'].max()], 
                'r--', alpha=0.5, label='Same time')
        ax3.set_xlabel('Stock Compile Time (s)')
        ax3.set_ylabel('Custom Compile Time (s)')
        ax3.set_title('Compilation Time Comparison')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # Plot 4: CX Reduction Distribution
        ax4 = axes[1, 0]
        ax4.hist(df['cx_reduction_percent'], bins=20, alpha=0.7, edgecolor='black')
        ax4.axvline(df['cx_reduction_percent'].mean(), color='red', 
                   linestyle='--', label=f'Mean: {df["cx_reduction_percent"].mean():.1f}%')
        ax4.set_xlabel('CX Reduction (%)')
        ax4.set_ylabel('Frequency')
        ax4.set_title('CX Reduction Distribution')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # Plot 5: Performance by Circuit Size Range
        ax5 = axes[1, 1]
        size_ranges = [(15, 25), (26, 50), (51, 75), (76, 150)]
        range_labels = ['Small\n(15-25q)', 'Medium\n(26-50q)', 'Large\n(51-75q)', 'XLarge\n(76q+)']
        range_means = []
        range_stds = []
        
        for (min_q, max_q) in size_ranges:
            subset = df[(df['num_qubits'] >= min_q) & (df['num_qubits'] <= max_q)]
            if not subset.empty:
                range_means.append(subset['cx_reduction_percent'].mean())
                range_stds.append(subset['cx_reduction_percent'].std())
            else:
                range_means.append(0)
                range_stds.append(0)
        
        bars = ax5.bar(range_labels, range_means, yerr=range_stds, 
                      capsize=5, alpha=0.7, color='skyblue', edgecolor='black')
        ax5.set_ylabel('Average CX Reduction (%)')
        ax5.set_title('Performance by Circuit Size')
        ax5.grid(True, alpha=0.3, axis='y')
        
        # Add value labels on bars
        for bar, mean in zip(bars, range_means):
            if mean > 0:
                ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                        f'{mean:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # Plot 6: Success Rate and Statistics
        ax6 = axes[1, 2]
        stats_labels = ['Total\nCircuits', 'Successful\nComparisons', 'Positive\nImprovements']
        stats_values = [
            len(metrics_df),
            len(df),
            (df['cx_reduction_percent'] > 0).sum()
        ]
        
        bars = ax6.bar(stats_labels, stats_values, alpha=0.7, 
                      color=['lightblue', 'lightgreen', 'gold'], edgecolor='black')
        ax6.set_ylabel('Count')
        ax6.set_title('Success Statistics')
        
        # Add value labels
        for bar, value in zip(bars, stats_values):
            ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    str(value), ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        if save_plots:
            plot_file = self.output_dir / "optimization_results.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            print(f"‚úÖ Plots saved to {plot_file}")
        
        if show_plots:
            plt.show()
        else:
            plt.close()
    
    def create_summary_table(self, metrics_df: pd.DataFrame) -> pd.DataFrame:
        """
        Create a summary table of key metrics.
        
        Args:
            metrics_df: DataFrame with transpilation metrics
            
        Returns:
            Summary DataFrame
        """
        if metrics_df.empty:
            return pd.DataFrame()
        
        df = metrics_df[metrics_df['custom_success'] & metrics_df['stock_success']].copy()
        
        if df.empty:
            return pd.DataFrame()
        
        # Create summary by circuit type/size
        summary_rows = []
        
        # Overall summary
        summary_rows.append({
            'Category': 'Overall',
            'Circuits': len(df),
            'Avg CX Reduction (%)': f"{df['cx_reduction_percent'].mean():.1f} ¬± {df['cx_reduction_percent'].std():.1f}",
            'Best CX Reduction (%)': f"{df['cx_reduction_percent'].max():.1f}",
            'Improvement Rate (%)': f"{(df['cx_reduction_percent'] > 0).mean() * 100:.1f}",
            'Avg Compile Time Ratio': f"{df['compile_time_ratio'].mean():.2f}"
        })
        
        # By size ranges
        size_ranges = [
            (15, 25, "Small (15-25q)"),
            (26, 50, "Medium (26-50q)"),
            (51, 75, "Large (51-75q)"),
            (76, 150, "XLarge (76q+)")
        ]
        
        for min_q, max_q, label in size_ranges:
            subset = df[(df['num_qubits'] >= min_q) & (df['num_qubits'] <= max_q)]
            if not subset.empty:
                summary_rows.append({
                    'Category': label,
                    'Circuits': len(subset),
                    'Avg CX Reduction (%)': f"{subset['cx_reduction_percent'].mean():.1f} ¬± {subset['cx_reduction_percent'].std():.1f}",
                    'Best CX Reduction (%)': f"{subset['cx_reduction_percent'].max():.1f}",
                    'Improvement Rate (%)': f"{(subset['cx_reduction_percent'] > 0).mean() * 100:.1f}",
                    'Avg Compile Time Ratio': f"{subset['compile_time_ratio'].mean():.2f}"
                })
        
        return pd.DataFrame(summary_rows)
    
    def export_hackathon_report(self, 
                               metrics_df: pd.DataFrame,
                               benchmark_names: List[str],
                               algorithm_description: str = "Custom Heavy-Hex Layout Optimization") -> None:
        """
        Create a comprehensive hackathon report.
        
        Args:
            metrics_df: DataFrame with results
            benchmark_names: List of benchmark suite names used
            algorithm_description: Description of the optimization algorithm
        """
        report_file = self.output_dir / "hackathon_report.md"
        
        with open(report_file, 'w') as f:
            f.write("# Quantum Layout Optimization - Hackathon Results\n\n")
            f.write(f"**Algorithm:** {algorithm_description}\n\n")
            f.write(f"**Target Backend:** IBM Brisbane (Heavy-Hex topology)\n\n")
            f.write(f"**Benchmark Suites:** {', '.join(benchmark_names)}\n\n")
            
            if not metrics_df.empty:
                df = metrics_df[metrics_df['custom_success'] & metrics_df['stock_success']]
                
                if not df.empty:
                    # Key results
                    f.write("## üéØ Key Results\n\n")
                    f.write(f"- **Total circuits tested:** {len(metrics_df)}\n")
                    f.write(f"- **Successful optimizations:** {len(df)}\n")
                    f.write(f"- **Average CX reduction:** {df['cx_reduction_percent'].mean():.1f}%\n")
                    f.write(f"- **Best CX reduction:** {df['cx_reduction_percent'].max():.1f}%\n")
                    f.write(f"- **Improvement rate:** {(df['cx_reduction_percent'] > 0).mean() * 100:.1f}%\n\n")
                    
                    # Performance table
                    f.write("## üìä Performance Summary\n\n")
                    summary_table = self.create_summary_table(metrics_df)
                    if not summary_table.empty:
                        f.write(summary_table.to_markdown(index=False))
                        f.write("\n\n")
                    
                    # Circuit size analysis
                    f.write("## üìè Scalability Analysis\n\n")
                    f.write(f"- **Smallest circuit:** {df['num_qubits'].min()} qubits\n")
                    f.write(f"- **Largest circuit:** {df['num_qubits'].max()} qubits\n")
                    f.write(f"- **Average circuit size:** {df['num_qubits'].mean():.1f} qubits\n\n")
                    
                    # Compilation time analysis
                    f.write("## ‚è±Ô∏è Compilation Performance\n\n")
                    f.write(f"- **Average custom time:** {df['custom_compile_time'].mean():.3f}s\n")
                    f.write(f"- **Average stock time:** {df['stock_compile_time'].mean():.3f}s\n")
                    f.write(f"- **Speed ratio:** {df['compile_time_ratio'].mean():.2f}x\n")
                    f.write(f"- **Faster compilations:** {(df['compile_time_ratio'] < 1.0).sum()}/{len(df)}\n\n")
            
            f.write("## üìà Visualizations\n\n")
            f.write("See `optimization_results.png` for detailed performance plots.\n\n")
            
            f.write("## üéâ Conclusion\n\n")
            f.write("The custom layout optimization successfully demonstrates improved performance ")
            f.write("over stock Qiskit transpilation on IBM Heavy-Hex architectures, ")
            f.write("achieving significant CX gate reductions across diverse quantum circuits.\n")
        
        print(f"‚úÖ Hackathon report saved to {report_file}")


if __name__ == "__main__":
    # Test results manager
    import pandas as pd
    
    # Create mock data
    mock_data = {
        'circuit_name': ['qv_15', 'qv_25', 'qv_50'],
        'num_qubits': [15, 25, 50],
        'custom_success': [True, True, True],
        'stock_success': [True, True, True],
        'cx_reduction_percent': [15.0, 25.0, 35.0],
        'stock_cx_count': [100, 200, 400],
        'custom_cx_count': [85, 150, 260],
        'stock_compile_time': [0.5, 1.0, 2.0],
        'custom_compile_time': [0.7, 1.2, 2.5],
        'compile_time_ratio': [1.4, 1.2, 1.25]
    }
    
    df = pd.DataFrame(mock_data)
    
    results = ResultsManager()
    results.create_comparison_plots(df, save_plots=False, show_plots=False)
    
    summary = results.create_summary_table(df)
    print("üìä Summary Table:")
    print(summary.to_string(index=False))
